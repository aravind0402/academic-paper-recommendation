{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcb0a329",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\pi96a\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import ast\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from itertools import chain\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "english_stop_words = list(stopwords.words('english'))\n",
    "import gensim.corpora as corpora\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from pprint import pprint\n",
    "import pyLDAvis.gensim\n",
    "import pickle\n",
    "import pyLDAvis\n",
    "import time\n",
    "from datetime import datetime\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f2ef2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Drive D/Datasets/Aminer Data\"\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb17fc22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dblp-ref-0.json',\n",
       " 'dblp-ref-1.json',\n",
       " 'dblp-ref-2.json',\n",
       " 'dblp-ref-3.json',\n",
       " 'new_dblp-ref-0.json',\n",
       " 'new_dblp-ref-1.json',\n",
       " 'new_dblp-ref-2.json',\n",
       " 'new_dblp-ref-3 LDA topic words.csv',\n",
       " 'new_dblp-ref-3.json']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48000460",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_file(file):\n",
    "    with open(file) as json_file:\n",
    "        data = json_file.readlines()\n",
    "    \n",
    "    data = [ast.literal_eval(d.strip(\"\\n\").strip(\"'\")) for d in data]\n",
    "    \n",
    "    json_filename = \"new_{}\".format(file)\n",
    "    if not os.path.isfile(\"new_{}\".format(json_filename)):\n",
    "        with open(json_filename, \"w\") as file:\n",
    "            json.dump(data, file)\n",
    "    \n",
    "    print(\"Completed file : {}\".format(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "386606ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#files = [f for f in os.listdir()]\n",
    "#\n",
    "#for file in files:\n",
    "#    convert_file(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f67ce7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#df1 = pd.read_json('new_dblp-ref-0.json')\n",
    "#df2 = pd.read_json('new_dblp-ref-1.json')\n",
    "#df3 = pd.read_json('new_dblp-ref-2.json')\n",
    "#df4 = pd.read_json('new_dblp-ref-3.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "579e92fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#df_all = pd.concat([df1, df2, df3, df4], axis = \"rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fae44b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Dropping NA :  (79007, 8)\n",
      "After Dropping NA :  (35174, 8)\n",
      "CPU times: total: 234 ms\n",
      "Wall time: 1.36 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_json(\"new_dblp-ref-3.json\")\n",
    "# drop all NA values from the dataset\n",
    "print(\"Before Dropping NA : \", df.shape)\n",
    "df = df.dropna().reset_index(drop = True)\n",
    "print(\"After Dropping NA : \", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8894dc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"n_references\"] = df[\"references\"].apply(lambda x: len(x))\n",
    "df[\"GT_zero_citations\"] = df[\"n_citation\"].apply(lambda x: \"Yes\" if x > 0 else \"No\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a530b663",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_authors = df[\"authors\"].tolist()\n",
    "flatten_all_authors = list(chain.from_iterable(all_authors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2c8a705",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Counter(flatten_all_authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ebb991c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThings to do:\\n- Build a content based recommendation system.\\n- Work on a hybrid approach using topic modelling and content of the papers.\\n- use authors and topic modelling scores to recommend papers.\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Things to do:\n",
    "- Build a content based recommendation system.\n",
    "- Work on a hybrid approach using topic modelling and content of the papers.\n",
    "- use authors and topic modelling scores to recommend papers.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191b37f3",
   "metadata": {},
   "source": [
    "### LDA Model and Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21f21e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating content column for each row in dataset\n",
    "df[\"Content\"] = df[\"abstract\"].str.lower() + df[\"title\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a82f8ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Creating stop words list\n",
    "stop_words_extended_list = [\"the\", \"of\", \"and\", \"a\", \"in\", \"to\", \"is\", \n",
    "                            \"?\", \"for\", \"we\", \"that\", \"-\", \"=\", \"with\", \",\", \n",
    "                            \"on\", \"as\", \"by\", \"are\", \"this\", \"be\", \".\", \n",
    "                            \"can\", \"an\", \"from\", \")\", \"which\", \"it\", \"+\", \n",
    "                            \"each\", \"our\", \"at\", \"where\", \"has\", \"such\", \n",
    "                            \"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\",\n",
    "                            \"j\", \"k\", \"l\", \"m\", \"n\", \"o\", \"p\", \"q\", \"r\",\n",
    "                            \"s\", \"t\", \"u\", \"v\", \"w\", \"x\", \"y\", \"z\", \n",
    "                            \"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \n",
    "                            \"9\", \"et\", \"j.\", \"\", \"(\", \"a)\", \"b)\"]\n",
    "english_stop_words.extend(stop_words_extended_list)\n",
    "english_stop_words = set(english_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76e43021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 906 ms\n",
      "Wall time: 2.37 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Tokenizing the documents after preprocessing\n",
    "full_string_list = []\n",
    "punctuations = [\",\", \".\", \"!\", \"!\",\"?\", \"=\", \"+\", \"??\", \":\", \"|\", \"<\", \">\", \"&\", \"?)\", \";\", \"[\", \"]\", \"?.\", \"al.\", \"}\", \"{\", \"~\", \"..\", \"(?\", \"_\", \"???\"]\n",
    "for sentence in df[\"Content\"].values:\n",
    "    temp_string_list = []\n",
    "    for words in sentence.split(\" \"):\n",
    "        if words not in english_stop_words and words not in punctuations:\n",
    "            temp_string_list.append(words)\n",
    "    full_string_list.append(temp_string_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2487a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2.36 s\n",
      "Wall time: 3.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# creating a dictionary from the tokenized documents\n",
    "id2word = corpora.Dictionary(full_string_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8d4006e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.33 s\n",
      "Wall time: 2.07 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Creating a bag of word representation for each document\n",
    "texts = full_string_list\n",
    "corpus = [id2word.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8c09751b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 13 s\n",
      "Wall time: 14.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Building an LDA model which has 5 clusters\n",
    "# number of topics\n",
    "num_topics = 6\n",
    "\n",
    "# building an LDA model\n",
    "lda_model = gensim.models.LdaModel(corpus = corpus, id2word = id2word, num_topics = num_topics)\n",
    "\n",
    "if not os.path.exists(\"new_dblp-ref-3 LDA.model\"):\n",
    "    lda_model.save(\"new_dblp-ref-3 LDA.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de5dcdce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 18.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# popular topics in LDA model\n",
    "topics = lda_model.show_topics(num_topics = num_topics, num_words = 80, formatted = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "267fdbf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# document topics \n",
    "document_topics = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "296f1490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 6.8 s\n",
      "Wall time: 9.77 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# creating document and topic dictionary\n",
    "document_topic_dict = dict()\n",
    "for i, doc_topics in enumerate(document_topics):\n",
    "    topic_index = []\n",
    "    topic_probs = []\n",
    "    for dt in doc_topics:\n",
    "        topic_index.append(dt[0])\n",
    "        topic_probs.append(dt[1])\n",
    "    \n",
    "    max_prob_index = np.argmax(topic_probs)\n",
    "    document_topic_dict[f\"Document {i + 1}\"] = doc_topics[max_prob_index][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "81e83446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 125 ms\n",
      "Wall time: 212 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "doc_topic_df = pd.DataFrame(document_topic_dict, index = [\"Topic\"]).T.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "73411c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "topic_words_dictionary = dict()\n",
    "for index, top_words in topics:\n",
    "    topic_words_dictionary[index] = []\n",
    "    for word in top_words:\n",
    "        topic_words_dictionary[index].append(word[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "be93cf00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([0, 1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dictionary to start with search using words\n",
    "topic_words_dictionary.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b479c25a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Topic\n",
       "5        11974\n",
       "1         6035\n",
       "0         5258\n",
       "3         5156\n",
       "4         5094\n",
       "2         1657\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_topic_df.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1a83334d",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_words_df = pd.DataFrame(topic_words_dictionary)\n",
    "topic_words_df.columns = [f\"Topic_{i}\" for i in range(6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "acc0d041",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_words_df.to_csv(\"new_dblp-ref-3 LDA topic words.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e52c385c",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_topic_df.to_csv(\"new_dblp-ref-3 doc-topic-df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5af78b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
